{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost [classifier + regressor] from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df = df.drop(\"Id\", axis=1)\n",
    "df = df.rename(columns={\"species\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        label\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Types of lables\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a00fc06550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency plot\n",
    "df['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.8, random_state=None):\n",
    "    train_df = df.sample(frac=test_size, random_state=random_state)\n",
    "    test_df = df[~df.index.isin(train_df.index)]\n",
    "    return train_df.sort_index(), test_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_classification(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_regression(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.sum((y_true - y_pred)**2) / len(y_true)) # RMSE\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DecisionStump()\n",
    "- BaseBoostingAlgorithm()\n",
    "- AdaBoostClassifier()\n",
    "- AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump():\n",
    "    def __init__(self):\n",
    "        # Feature/Attribute Index to consider for splitting\n",
    "        self.decision_feature_index = None\n",
    "        # Exact value from Feature/Attribute to split on\n",
    "        self.decision_threshold_value = None\n",
    "        # Stump importance / weight\n",
    "        self.weight = None\n",
    "        # Stump error\n",
    "        self.error = None\n",
    "        # Left leaf value\n",
    "        self.left_leaf_value = None\n",
    "        # Right leaf value\n",
    "        self.right_leaf_value = None\n",
    "        # Stump decision compartor \n",
    "        self.decision_comparator = None\n",
    "        print(\"New Stump Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseBoostingAlgorithm():\n",
    "    def __init__(self, n_learners):\n",
    "        self.n_learners = n_learners\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Store all weak learners (Weak learner -> A decsion stump)\n",
    "        self.learners = []\n",
    "        # Identify each feature type in input X and store as list\n",
    "        self.feature_types = self._determine_type_of_feature(X)\n",
    "        # Concatenate input and output\n",
    "        self.data = np.concatenate((X, np.expand_dims(y, axis=1)), axis=1)\n",
    "        # Initialize weight for each example as 1/N (where N -> total number of examples)\n",
    "        self.sample_weight = np.full(len(self.data), (1 / len(self.data)))\n",
    "        \n",
    "        print(self.learners)\n",
    "        print(self.feature_types)\n",
    "        print(self.ml_task)\n",
    "        \n",
    "        # Iterate and build learners\n",
    "        for i_boost in range(self.n_learners):\n",
    "            # Instantiate a new decision stump object\n",
    "            learner = DecisionStump()\n",
    "\n",
    "            # Find and Perform split over best feature \n",
    "            potential_splits = self._get_potential_splits(self.data)\n",
    "            #print('Here is to new')\n",
    "            #print(self.sample_weight)\n",
    "            #print('Here is to the new')\n",
    "            split_column_index, split_value = self._determine_best_split(self.data, self.sample_weight, potential_splits, self.ml_task)\n",
    "            left_node_data, right_node_data = self._split_data(self.data, split_column_index, split_value)\n",
    "            print(f'split_column_index: {split_column_index}, split_value: {split_value}')\n",
    "\n",
    "            # Compute Leaf values\n",
    "            left_leaf_value = self._create_leaf(left_node_data, self.ml_task)\n",
    "            right_leaf_value = self._create_leaf(right_node_data, self.ml_task)\n",
    "            print(f'Left leaf: {left_leaf_value}, Right leaf: {right_leaf_value}')\n",
    "\n",
    "            # Allocate the instantiated learner with our computed values\n",
    "            learner.decision_feature_index = split_column_index\n",
    "            learner.decision_threshold_value = split_value\n",
    "            learner.left_leaf_value = left_leaf_value\n",
    "            learner.right_leaf_value = right_leaf_value\n",
    "            learner.decision_comparator = self.feature_types[split_column_index]\n",
    "            \n",
    "            # Boosting step\n",
    "            self.sample_weight, learner = self.boost(i_boost,\n",
    "                                              self.data,\n",
    "                                              self.sample_weight,\n",
    "                                              learner)\n",
    "            # Early Termination\n",
    "            if self.sample_weight is None:\n",
    "                break\n",
    "            # Stop boosting since error is 0\n",
    "            # Stop if the sum of sample weights has become non-positive\n",
    "            if learner.error == 0 or np.sum(self.sample_weight) <= 0:\n",
    "                self.learners.append(learner)\n",
    "                break\n",
    "            print(f'{i_boost}: Sample weight(sum) {np.sum(self.sample_weight)}')\n",
    "            # Dont perform operations in below conditional block if we are on final learner\n",
    "            if not i_boost == self.n_learners - 1:\n",
    "                # Normalize\n",
    "                self.sample_weight /= np.sum(self.sample_weight)\n",
    "                # Construct new data set sample based on sample_weight\n",
    "#                 self.data = self._sample_data_by_weights(self.data, self.sample_weight)\n",
    "                # Reinitialize equal sample weights for the new data\n",
    "#                 self.sample_weight = np.full(len(self.data), (1 / len(self.data)))\n",
    "            \n",
    "            # Add this learner to our main list of learners\n",
    "            self.learners.append(learner)\n",
    "            print(f'Total stumps: {len(self.learners)}')\n",
    "            \n",
    "        return self  \n",
    "            \n",
    "    def stump_predict(self, data, learner):\n",
    "        \"\"\"\n",
    "        Computes prediction for the passed data examples w.r.t to the learner(descision stump) \n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        feature_column = data[:, learner.decision_feature_index]\n",
    "        for value in feature_column:\n",
    "            if learner.decision_comparator == 'categorical':\n",
    "                if value == learner.decision_threshold_value: # Left node\n",
    "                    pred = learner.left_leaf_value\n",
    "                else: # right node\n",
    "                    pred = learner.right_leaf_value\n",
    "            else: # continuous\n",
    "                if value <= learner.decision_threshold_value: # Left node\n",
    "                    pred = learner.left_leaf_value\n",
    "                else: # right node\n",
    "                    pred = learner.right_leaf_value\n",
    "            preds.append(pred)\n",
    "        return preds\n",
    "    \n",
    "    \n",
    "    def _calculate_weighted_mse(self, data):\n",
    "        \"\"\"\n",
    "        Calculate weighted mean squared error\n",
    "        \"\"\"\n",
    "        actual_values = data[:, -2]\n",
    "        data_sample_weight =  data[:, -1]\n",
    "        \n",
    "        if len(actual_values) == 0:   # empty data\n",
    "            mse = 0\n",
    "\n",
    "        else:\n",
    "            prediction = np.mean(actual_values)\n",
    "            # Not normalizing using sum of weighted mean, beacuse the sum of weighted mean is 1\n",
    "            weighted_mse = np.mean((data_sample_weight * (actual_values - prediction))**2)\n",
    "\n",
    "        return weighted_mse\n",
    "    \n",
    "    \n",
    "    def _calculate_weighted_gini_index(self, data):\n",
    "        \"\"\"\n",
    "        Calculate weighted gini index\n",
    "        \"\"\"\n",
    "        #print('_calculate_weighted_gini_index() called !')\n",
    "        label_column = data[:, -2]\n",
    "        data_sample_weight =  data[:, -1]\n",
    "        #_, counts = np.unique(label_column, return_counts=True)\n",
    "        _, value_indexes, counts = np.unique(label_column, return_counts=True, return_index=True)\n",
    "        # Get summed weights for each class\n",
    "        class_weights = np.array([np.take(data_sample_weight, np.where(label_column == label_column[value_index])[0]).sum() for value_index in value_indexes])\n",
    "    \n",
    "        #probabilities = counts / counts.sum()\n",
    "        weighted_classes = counts * class_weights\n",
    "        normalized_weighted_classes = weighted_classes / sum(weighted_classes)\n",
    "        \n",
    "        weighted_gini_impurity = -(1 + sum(normalized_weighted_classes**2))\n",
    "\n",
    "        return weighted_gini_impurity\n",
    "    \n",
    "    \n",
    "    def _calculate_weighted_overall_metric(self, data, left_node_data, right_node_data, metric_function):\n",
    "        \"\"\"\n",
    "        Generalized impurity metric, computes weighted overall\n",
    "        impurity/error w.r.t left and right nodes\n",
    "        \"\"\"\n",
    "        # Labels\n",
    "        left_label_column = left_node_data[:, -2]\n",
    "        right_label_column = right_node_data[:, -2]\n",
    "        parent_label_column = data[:, -2]\n",
    "        # Sample weights\n",
    "        left_sample_weight = left_node_data[:, -1]\n",
    "        right_sample_weight = right_node_data[:, -1]\n",
    "        parent_sample_weight = data[:, -1]\n",
    "        \n",
    "        if self.ml_task == 'classification':\n",
    "            #print('_calculate_weighted_overall_metric() -> classification!')\n",
    "            _, left_value_indexes, left_counts = np.unique(left_label_column, return_counts=True, return_index=True)\n",
    "            _, right_value_indexes, right_counts = np.unique(right_label_column, return_counts=True, return_index=True)\n",
    "            _, parent_value_indexes, parent_counts = np.unique(parent_label_column, return_counts=True, return_index=True)\n",
    "            \n",
    "            left_class_weights = np.array([np.take(left_sample_weight, np.where(left_label_column == left_label_column[value_index])[0]).sum() for value_index in left_value_indexes])\n",
    "            right_class_weights = np.array([np.take(right_sample_weight, np.where(right_label_column == right_label_column[value_index])[0]).sum() for value_index in right_value_indexes])\n",
    "            parent_class_weights = np.array([np.take(parent_sample_weight, np.where(parent_label_column == parent_label_column[value_index])[0]).sum() for value_index in parent_value_indexes])\n",
    "            \n",
    "            # class count * class weight, for respective classes\n",
    "            left_weighted_classes = left_counts * left_class_weights\n",
    "            right_weighted_classes = right_counts * right_class_weights\n",
    "            parent_weighted_classes = parent_counts * parent_class_weights\n",
    "            \n",
    "            # Weighted probabilities of left and right node\n",
    "            #print(f'DEBUG 3: {np.sum(left_weighted_classes) == np.sum(left_sample_weight)}')\n",
    "            #print(f'DEBUG 4: {np.sum(right_weighted_classes) == np.sum(right_sample_weight)}')\n",
    "            #total_parent_class_weight = (np.sum(left_weighted_classes) + np.sum(right_weighted_classes))\n",
    "            #print(f'DEBUG 5: {np.sum(total_parent_class_weight) == (np.sum(left_sample_weight) + np.sum(right_sample_weight))}')\n",
    "            #total_parent_class_weight = (np.sum(left_class_weights) + np.sum(right_class_weights))\n",
    "            #print(f'Left gini index: {metric_function(left_node_data)}')\n",
    "            #print(f'Right gini index: {metric_function(right_node_data)}')\n",
    "            #print(f'DEBUG 3: {np.sum(left_weighted_classes)} / {np.sum(parent_weighted_classes)}')\n",
    "            #print(f'DEBUG 4: {np.sum(right_weighted_classes)} / {np.sum(parent_weighted_classes)}')\n",
    "            \n",
    "            weighted_prob_node_left = np.divide(np.sum(left_weighted_classes), np.sum(parent_weighted_classes))\n",
    "            weighted_prob_node_right = np.divide(np.sum(right_weighted_classes), np.sum(parent_weighted_classes))\n",
    "\n",
    "            #total_parent_class_weight = (np.sum(left_class_weights * left_counts) + np.sum(right_class_weights * right_counts))\n",
    "            #weighted_prob_node_left = np.sum(left_weighted_classes) / total_parent_class_weight\n",
    "            #weighted_prob_node_right = np.sum(right_weighted_classes) / total_parent_class_weight\n",
    "            #print(f\"11: {weighted_prob_node_left} == {weighted_prob_node_left_1}\")\n",
    "            #print(f\"11: {weighted_prob_node_right} == {weighted_prob_node_right_2}\")\n",
    "\n",
    "            #print(f'DEBUG 6: {weighted_prob_node_left == (np.sum(left_sample_weight) / (np.sum(left_sample_weight) + np.sum(right_sample_weight)))}')\n",
    "            #print(f'DEBUG 7: {weighted_prob_node_right == (np.sum(right_sample_weight) / (np.sum(left_sample_weight) + np.sum(right_sample_weight)))}')\n",
    "        else:\n",
    "            total_parent_sample_weight = np.sum(np.sum(left_sample_weight), np.sum(right_sample_weight))\n",
    "            # Weighted probabilities of left and right node\n",
    "            weighted_prob_node_left = np.sum(left_sample_weight) / total_parent_sample_weight\n",
    "            weighted_prob_node_right = np.sum(right_sample_weight) / total_parent_sample_weight\n",
    "        \n",
    "        # Compute final overall metric\n",
    "        overall_metric =  (weighted_prob_node_left * metric_function(left_node_data) \n",
    "                         + weighted_prob_node_right * metric_function(right_node_data))\n",
    "\n",
    "        return overall_metric\n",
    "        \n",
    "    \n",
    "    def _sample_data_by_weights(self, data, sample_weight):\n",
    "        \"\"\"\n",
    "        Construct an new input, iteratively sampled over distribution \n",
    "        formed by passed sample_weight.\n",
    "\n",
    "        Note: \n",
    "        Learn more about this technique: https://youtu.be/LsK-xG1cLYA (Statquest)\n",
    "        \"\"\"\n",
    "        n_samples, _ = np.shape(data)\n",
    "        # Intialize array to hold sampled index  \n",
    "        sampled_indices = []\n",
    "        # Perform cumulative summation over sample_weight to create buckets\n",
    "        sample_weight_buckets = np.cumsum(sample_weight)\n",
    "        # Keeping sampling 'n_samples' times\n",
    "        for _ in range(n_samples):\n",
    "            # Generate a random number between 0 and 1\n",
    "            random_num = np.random.random_sample()\n",
    "            # Find the bucket Eg: weight buckets [0.33, 0.66, 0.99] and random number = 0.47\n",
    "            # then index 1 will be selected (since cumsum value is 0.66)\n",
    "            bucket_index = np.where(sample_weight_buckets > random_num)[0][0]\n",
    "\n",
    "            sampled_indices.append(bucket_index)\n",
    "        # finally construct weighted data using sampled_indexes\n",
    "        weighted_data = data[sampled_indices]\n",
    "\n",
    "        return weighted_data\n",
    "\n",
    "\n",
    "    def _get_potential_splits(self, data):\n",
    "        \"\"\"\n",
    "        Get all potential splits for each feature\n",
    "        Splits can be made on each unique value\n",
    "        Can essentially make a split at each unique value\n",
    "        \n",
    "        \"\"\"\n",
    "        potential_splits = {}\n",
    "        _, n_columns = data.shape\n",
    "        for column_index in range(n_columns - 1): # excluding the last column which is the label\n",
    "            values = data[:, column_index]\n",
    "            unique_values = np.unique(values)\n",
    "\n",
    "            potential_splits[column_index] = unique_values\n",
    "\n",
    "        return potential_splits\n",
    "    \n",
    "    \n",
    "    def _calculate_gini_index(self, data):\n",
    "        \"\"\"\n",
    "        Calculate gini index\n",
    "        \"\"\"\n",
    "        label_column = data[:, -1]\n",
    "        _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "        probabilities = counts / counts.sum()\n",
    "        gini_impurity = - (1 + sum(probabilities**2))\n",
    "\n",
    "        return gini_impurity\n",
    "    \n",
    "    \n",
    "    def _calculate_mse(self, data):\n",
    "        \"\"\"\n",
    "        Calculate mean squared error\n",
    "        \"\"\"\n",
    "        actual_values = data[:, -1]\n",
    "        if len(actual_values) == 0:   # empty data\n",
    "            mse = 0\n",
    "\n",
    "        else:\n",
    "            prediction = np.mean(actual_values)\n",
    "            mse = np.mean((actual_values - prediction) **2)\n",
    "\n",
    "        return mse\n",
    "    \n",
    "    \n",
    "    def _calculate_overall_metric(self, left_node_data, right_node_data, metric_function):\n",
    "        \"\"\"\n",
    "        Generalized impurity metric, computes weighted overall\n",
    "        impurity/error w.r.t left and right nodes\n",
    "        \"\"\"\n",
    "        n = len(left_node_data) + len(right_node_data)\n",
    "        # Probabilities of left and right node\n",
    "        prob_node_left = len(left_node_data) / n\n",
    "        prob_node_right = len(right_node_data) / n\n",
    "\n",
    "        overall_metric =  (prob_node_left * metric_function(left_node_data) \n",
    "                         + prob_node_right * metric_function(right_node_data))\n",
    "\n",
    "        return overall_metric\n",
    "    \n",
    "    def _determine_best_split(self, data, sample_weight, potential_splits, ml_task):\n",
    "        \"\"\"\n",
    "        Iterate over each column_index (as keys) in potential_split (dict)\n",
    "        Perform split(of examples) over each unique value and evaluate the split\n",
    "        Identify the best split and return its feature index and value\n",
    "        \"\"\"\n",
    "        # Stitch data with sample_weight towards the end\n",
    "        data = np.concatenate((data, np.expand_dims(sample_weight, axis=1)), axis=1)\n",
    "#         print(data[:, -2])\n",
    "#         print(data[:, -1])\n",
    "        # Best minimum gini index to be updated iteratively\n",
    "        best_overall_metric = float('inf')\n",
    "        \n",
    "        for column_index in potential_splits:\n",
    "            for value in potential_splits[column_index]:\n",
    "                left_node_data, right_node_data = self._split_data(data, split_column_index=column_index, split_value=value)\n",
    "\n",
    "                if ml_task == \"regression\":\n",
    "                    current_overall_metric = self._calculate_weighted_overall_metric(data, left_node_data, right_node_data,\n",
    "                                                                                     metric_function=self._calculate_weighted_mse)\n",
    "                else: # classification\n",
    "                    current_overall_metric = self._calculate_weighted_overall_metric(data, left_node_data, right_node_data,\n",
    "                                                                                     metric_function=self._calculate_weighted_gini_index)\n",
    "                print(column_index, value, current_overall_metric)\n",
    "                # If a lower overall_metric is achieved update the index and value with the current\n",
    "                if current_overall_metric <= best_overall_metric:\n",
    "                    best_overall_metric = current_overall_metric\n",
    "                    best_split_column_index = column_index\n",
    "                    best_split_value = value\n",
    "                    #print(best_overall_metric)\n",
    "\n",
    "        return best_split_column_index, best_split_value\n",
    "    \n",
    "    \n",
    "    def _split_data(self, data, split_column_index, split_value):\n",
    "        \"\"\" \n",
    "        Split data(examples) based on best split_column_index and split_value\n",
    "        estimated using task specific splitting metric.\n",
    "        \"\"\"\n",
    "        # Get values(from feature column) for the passed split_column index\n",
    "        split_column_values = data[:, split_column_index]\n",
    "\n",
    "        type_of_feature = self.feature_types[split_column_index]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            left_node_data = data[split_column_values <= split_value]\n",
    "            right_node_data = data[split_column_values >  split_value]\n",
    "\n",
    "        # feature is categorical   \n",
    "        else:\n",
    "            left_node_data = data[split_column_values == split_value]\n",
    "            right_node_data = data[split_column_values != split_value]\n",
    "        return left_node_data, right_node_data\n",
    "    \n",
    "    \n",
    "    def _create_leaf(self, data, ml_task):\n",
    "        \"\"\"\n",
    "        Create leaf node, with leaf value based on ml_task\n",
    "        for,\n",
    "        Classfication: consider majority vote\n",
    "        Regression: consider the mean value\n",
    "        \"\"\"\n",
    "        label_column = data[:, -1]\n",
    "        if ml_task == \"regression\":\n",
    "            leaf = np.mean(label_column)\n",
    "\n",
    "        # classfication    \n",
    "        else:\n",
    "            unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "            index = counts_unique_classes.argmax()\n",
    "            leaf = unique_classes[index]\n",
    "\n",
    "        return leaf\n",
    "    \n",
    "    \n",
    "    def _determine_type_of_feature(self, X):\n",
    "        \"\"\"\n",
    "        Determine, if the feature is categorical or continuous\n",
    "        \"\"\"\n",
    "        feature_types = []\n",
    "        n_unique_values_treshold = 15 # Threshold for a numeric feature to be categorical\n",
    "        \n",
    "        n_samples, n_features = np.shape(X)\n",
    "        \n",
    "        for feature_i in range(n_features):\n",
    "            unique_values = np.unique(X[:, feature_i])\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "\n",
    "        return feature_types\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class AdaBoostClassifier(BaseBoostingAlgorithm):\n",
    "    def __init__(self, n_learners=20):\n",
    "        # Set total number of weak learners\n",
    "        super().__init__(n_learners)\n",
    "        self.ml_task = \"classification\"\n",
    "        self.classes = None\n",
    "        self.n_classes = None\n",
    "        \n",
    "    def boost(self, i_boost, data, sample_weight, learner):\n",
    "        \"\"\"\n",
    "        Compute learner importance and error, along with boosted weights for each example \n",
    "        \"\"\"\n",
    "        print(f'Boost Called')\n",
    "        \n",
    "        # If its first boost initialize number of classes(n_classes)\n",
    "        if i_boost == 0:\n",
    "            self.classes = np.unique(data[:, -1])\n",
    "            self.n_classes = self.classes.size\n",
    "        #print(f'DEBUG 1: {self.classes}')\n",
    "        # Perform predictions\n",
    "        preds = self.stump_predict(self.data, learner)\n",
    "        \n",
    "        # Incorrectly classified examples\n",
    "        incorrect = preds != data[:, -1]\n",
    "        #print(f'DEBUG 2: {self.classes}')\n",
    "        #print(incorrect)\n",
    "        # Learner Error\n",
    "        learner_error = np.mean(np.average(incorrect, weights=sample_weight, axis=0))\n",
    "        # Stop if classification is perfect\n",
    "        if learner_error <= 0:\n",
    "            learner.weight = 1\n",
    "            learner.error = 0\n",
    "            return sample_weight, learner\n",
    "        print(f'Learner error: {learner_error}')\n",
    "        \n",
    "        # Learner weight\n",
    "        learner_weight = (np.log((1 - learner_error) / (learner_error)) +\n",
    "                        np.log(self.n_classes - 1))\n",
    "        print(f'Learner weight: {learner_weight}')\n",
    "        \n",
    "        # Boost sample_weight for each each sample\n",
    "        # Dont boost sample_weight if we are on final learner\n",
    "        #print(f'#### Sample Weights before')\n",
    "        #print(sample_weight)\n",
    "        if not i_boost == self.n_learners - 1:\n",
    "        # Boost only positive weights\n",
    "            sample_weight *= np.exp(learner_weight * incorrect *\n",
    "                                    ((sample_weight > 0) |\n",
    "                                     (learner_weight < 0)))\n",
    "        \n",
    "        #print(f'#### Sample Weights After')\n",
    "       # print(sample_weight)\n",
    "        # Allocate learner its computed weight and error\n",
    "        learner.weight = learner_weight\n",
    "        learner.error = learner_error\n",
    "        \n",
    "        # Finally return sample weights and boosted learner\n",
    "        return sample_weight, learner\n",
    "         \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict classes for X.\n",
    "        \"\"\"\n",
    "        print(f'Predict called')\n",
    "        \n",
    "        # Get activated matrix for with respect to each learner [get vote of each learner]\n",
    "        # Add each activated matrix (matrix addition) [get overall vote of all leaners]\n",
    "        # return the overall matrix\n",
    "        # Argmax is used over each row of overall matrix to figure our the class\n",
    "        classes = self.classes[:, np.newaxis]\n",
    "        pred = sum((self.stump_predict(X, learner) == classes).T * learner.weight\n",
    "                   for learner in self.learners)\n",
    "        # Normalize \n",
    "        learner_weights = sum(learner.weight for learner in self.learners)\n",
    "        pred /= learner_weights\n",
    "        \n",
    "        # If its binary classification obatin the form [-, +], convienient to select classes with np.take() \n",
    "        # Eg(binary): classes =  [[c1], [c2]] and pred = [True, False, True], below output: [[c2], [c1], [c2]]\n",
    "        if self.n_classes == 2:\n",
    "            pred[:, 0] *= -1\n",
    "            pred = pred.sum(axis=1)\n",
    "            return classes.take(pred > 0, axis=0)\n",
    "        # Finds index of column with max value, and uses this index to select class from classes\n",
    "        #print(f'Classes ({classes.shape}): {classes}')\n",
    "        #print(f'Classes ({pred.shape}): {pred}')\n",
    "        #print(f'Classes element ({pred[0].shape}): {pred}')\n",
    "        return classes.take(np.argmax(pred, axis=1), axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['continuous', 'continuous', 'continuous', 'continuous']\n",
      "classification\n",
      "New Stump Created!\n",
      "0 4.3 -1.3161177138224565\n",
      "0 4.4 -1.271175267003935\n",
      "0 4.5 -1.2584104389086594\n",
      "0 4.6 -1.218257626103877\n",
      "0 4.7 -1.2046202320707458\n",
      "0 4.8 -1.1887490578297597\n",
      "0 4.9 -1.155479740546653\n",
      "0 5.0 -1.1730436760193008\n",
      "0 5.1 -1.2649012762256495\n",
      "0 5.2 -1.3016956788176184\n",
      "0 5.3 -1.3211644171519048\n",
      "0 5.4 -1.4125723892660849\n",
      "0 5.5 -1.3888928912631786\n",
      "0 5.6 -1.314189200581299\n",
      "0 5.7 -1.309794918675283\n",
      "0 5.8 -1.25990507826904\n",
      "0 5.9 -1.236940888995445\n",
      "0 6.0 -1.2035746477008\n",
      "0 6.1 -1.187359722539453\n",
      "0 6.2 -1.167893381464814\n",
      "0 6.3 -1.1086712123449063\n",
      "0 6.4 -1.0805271909750003\n",
      "0 6.5 -1.0676329126516828\n",
      "0 6.6 -1.0968105157677572\n",
      "0 6.7 -1.133420764237919\n",
      "0 6.8 -1.1526903185790758\n",
      "0 6.9 -1.1806968114996879\n",
      "0 7.0 -1.1993822470515207\n",
      "0 7.1 -1.2046202320707458\n",
      "0 7.2 -1.2266742361521783\n",
      "0 7.3 -1.2361669148780845\n",
      "0 7.4 -1.2467432525951558\n",
      "0 7.6 -1.2584104389086594\n",
      "0 7.7 -1.3161177138224562\n",
      "0 7.9 -1.3333333333333333\n",
      "1 2.0 -1.3161177138224565\n",
      "1 2.2 -1.2672477074542898\n",
      "1 2.3 -1.2103401977785069\n",
      "1 2.4 -1.1812507923410438\n",
      "1 2.5 -1.0887320050441365\n",
      "1 2.6 -1.0506658774201505\n",
      "1 2.7 -1.0055972848731471\n",
      "1 2.8 -0.9839208944187404\n",
      "1 2.9 -1.0328326739333933\n",
      "1 3.0 -1.0693270607632022\n",
      "1 3.1 -1.0704887940299184\n",
      "1 3.2 -1.1185398907103827\n",
      "1 3.3 -1.1606378667029476\n",
      "1 3.4 -1.1420194594594595\n",
      "1 3.5 -1.1350875217132044\n",
      "1 3.6 -1.1582941158073243\n",
      "1 3.7 -1.1745243069235574\n",
      "1 3.8 -1.2467432525951558\n",
      "1 3.9 -1.271175267003935\n",
      "1 4.0 -1.2850441392703567\n",
      "1 4.1 -1.3000230741146404\n",
      "1 4.2 -1.3161177138224565\n",
      "1 4.4 -1.3333333333333333\n",
      "2 1.0 -1.3161177138224565\n",
      "2 1.1 -1.3000230741146404\n",
      "2 1.2 -1.271175267003935\n",
      "2 1.3 -1.2046202320707458\n",
      "2 1.4 -1.208219328562286\n",
      "2 1.5 -1.3774384213580966\n",
      "2 1.6 -1.5187181360868414\n",
      "2 1.7 -1.614667306155076\n",
      "2 1.9 -1.6666666666666665\n",
      "2 3.0 -1.647000093021351\n",
      "2 3.3 -1.609674128933955\n",
      "2 3.5 -1.5750567984975292\n",
      "2 3.6 -1.5587834672628782\n",
      "2 3.7 -1.5432143780747656\n",
      "2 3.8 -1.528361961015026\n",
      "2 3.9 -1.4882468672940292\n",
      "2 4.0 -1.4371461306622035\n",
      "2 4.1 -1.4166366186116814\n",
      "2 4.2 -1.4018589409562559\n",
      "2 4.3 -1.4\n",
      "2 4.4 -1.4074199743039157\n",
      "2 4.5 -1.428929993391009\n",
      "2 4.6 -1.4619681067372907\n",
      "2 4.7 -1.5324546376855421\n",
      "2 4.8 -1.5150263429092012\n",
      "2 4.9 -1.4800515657038993\n",
      "2 5.0 -1.4342613655533283\n",
      "2 5.1 -1.327827092846271\n",
      "2 5.2 -1.298610167793639\n",
      "2 5.3 -1.2725925925925927\n",
      "2 5.4 -1.2498765864332606\n",
      "2 5.5 -1.2222222222222223\n",
      "2 5.6 -1.191318772018118\n",
      "2 5.7 -1.1887490578297597\n",
      "2 5.8 -1.1951859318574345\n",
      "2 5.9 -1.2046202320707458\n",
      "2 6.0 -1.218257626103877\n",
      "2 6.1 -1.2467432525951558\n",
      "2 6.3 -1.2584104389086594\n",
      "2 6.4 -1.271175267003935\n",
      "2 6.6 -1.2850441392703567\n",
      "2 6.7 -1.3161177138224562\n",
      "2 6.9 -1.3333333333333333\n",
      "3 0.1 -1.2467432525951558\n",
      "3 0.2 -1.327827092846271\n",
      "3 0.3 -1.4539249229154367\n",
      "3 0.4 -1.614667306155076\n",
      "3 0.5 -1.6403333733253351\n",
      "3 0.6 -1.6666666666666665\n",
      "3 1.0 -1.5432143780747656\n",
      "3 1.1 -1.5008630393996247\n",
      "3 1.2 -1.4457147548385771\n",
      "3 1.3 -1.404178904298361\n",
      "3 1.4 -1.4195604370842139\n",
      "3 1.5 -1.498062371100569\n",
      "3 1.6 -1.5266773099506772\n",
      "3 1.7 -1.5220248169653219\n",
      "3 1.8 -1.327827092846271\n",
      "3 1.9 -1.2608153893279423\n",
      "3 2.0 -1.208219328562286\n",
      "3 2.1 -1.1886195653363991\n",
      "3 2.2 -1.1920216857263872\n",
      "3 2.3 -1.2467432525951558\n",
      "3 2.4 -1.2850441392703567\n",
      "3 2.5 -1.3333333333333333\n",
      "split_column_index: 3, split_value: 0.6\n",
      "Left leaf: Iris-setosa, Right leaf: Iris-versicolor\n",
      "Boost Called\n",
      "Learner error: 0.3333333333333332\n",
      "Learner weight: 1.386294361119891\n",
      "0: Sample weight(sum) 2.0\n",
      "Total stumps: 1\n",
      "New Stump Created!\n",
      "0 4.3 -1.4946844909737604\n",
      "0 4.4 -1.4815846743295022\n",
      "0 4.5 -1.4781526104417673\n",
      "0 4.6 -1.468978887243495\n",
      "0 4.7 -1.4670611416209025\n",
      "0 4.8 -1.4697546572934979\n",
      "0 4.9 -1.4241300803114885\n",
      "0 5.0 -1.452130666791556\n",
      "0 5.1 -1.508538104318885\n",
      "0 5.2 -1.5328755547014419\n",
      "0 5.3 -1.5429582094634506\n",
      "0 5.4 -1.5944044998424531\n",
      "0 5.5 -1.6038007411467599\n",
      "0 5.6 -1.544387777207927\n",
      "0 5.7 -1.5178280020697026\n",
      "0 5.8 -1.3911343288925613\n",
      "0 5.9 -1.3498432090013748\n",
      "0 6.0 -1.2760612390043051\n",
      "0 6.1 -1.2145137134061785\n",
      "0 6.2 -1.1541934554703017\n",
      "0 6.3 -1.0072593068581563\n",
      "0 6.4 -0.9410520398636637\n",
      "0 6.5 -0.9246784000000001\n",
      "0 6.6 -0.9376343779634375\n",
      "0 6.7 -0.9798726423296384\n",
      "0 6.8 -1.0112913953313056\n",
      "0 6.9 -1.0719318598149643\n",
      "0 7.0 -1.078930363771344\n",
      "0 7.1 -1.1012836761698548\n",
      "0 7.2 -1.1822989604069898\n",
      "0 7.3 -1.2139446272991292\n",
      "0 7.4 -1.2479040803515387\n",
      "0 7.6 -1.2841730279898225\n",
      "0 7.7 -1.4522526431114764\n",
      "0 7.9 -1.5000000000000004\n",
      "1 2.0 -1.4946844909737604\n",
      "1 2.2 -1.4370215049255923\n",
      "1 2.3 -1.4208412931850434\n",
      "1 2.4 -1.4143786344218676\n",
      "1 2.5 -1.2302502767637058\n",
      "1 2.6 -1.1518629941417364\n",
      "1 2.7 -1.0252000000000006\n",
      "1 2.8 -0.8816825665751051\n",
      "1 2.9 -0.8791099340390964\n",
      "1 3.0 -0.9488137990513157\n",
      "1 3.1 -1.0209602121320918\n",
      "1 3.2 -1.169058624882744\n",
      "1 3.3 -1.2855603706082013\n",
      "1 3.4 -1.3364966157974905\n",
      "1 3.5 -1.3235752765126876\n",
      "1 3.6 -1.3691758279027983\n",
      "1 3.7 -1.370694332977699\n",
      "1 3.8 -1.4751804932114163\n",
      "1 3.9 -1.4815846743295022\n",
      "1 4.0 -1.4854811068053577\n",
      "1 4.1 -1.489846275781321\n",
      "1 4.2 -1.4946844909737604\n",
      "1 4.4 -1.5000000000000004\n",
      "2 1.0 -1.4946844909737604\n",
      "2 1.1 -1.489846275781321\n",
      "2 1.2 -1.4815846743295022\n",
      "2 1.3 -1.4670611416209025\n",
      "2 1.4 -1.4905846448459197\n",
      "2 1.5 -1.5863911595232463\n",
      "2 1.6 -1.658912912146352\n",
      "2 1.7 -1.707285476647473\n",
      "2 1.9 -1.7333333333333336\n",
      "2 3.0 -1.7286488289483821\n",
      "2 3.3 -1.719961505475747\n",
      "2 3.5 -1.7121674454347724\n",
      "2 3.6 -1.7086036169067134\n",
      "2 3.7 -1.7052630266806048\n",
      "2 3.8 -1.7021476712669323\n",
      "2 3.9 -1.6941850848501714\n",
      "2 4.0 -1.6858087591673907\n",
      "2 4.1 -1.6839741378388338\n",
      "2 4.2 -1.6855893854687465\n",
      "2 4.3 -1.6882352941176475\n",
      "2 4.4 -1.6973765413469144\n",
      "2 4.5 -1.673505684210527\n",
      "2 4.6 -1.6909051972728293\n",
      "2 4.7 -1.7266730604463387\n",
      "2 4.8 -1.6420216261371194\n",
      "2 4.9 -1.5184114852563377\n",
      "2 5.0 -1.3995049895234881\n",
      "2 5.1 -1.1680733067729085\n",
      "2 5.2 -1.1160108428631936\n",
      "2 5.3 -1.0721212121212123\n",
      "2 5.4 -1.0367049596309112\n",
      "2 5.5 -1.0\n",
      "2 5.6 -0.9877441881501582\n",
      "2 5.7 -1.0128339152119703\n",
      "2 5.8 -1.0589073692248954\n",
      "2 5.9 -1.1012836761698548\n",
      "2 6.0 -1.1529711361310135\n",
      "2 6.1 -1.2479040803515387\n",
      "2 6.3 -1.2841730279898225\n",
      "2 6.4 -1.3227469994058232\n",
      "2 6.6 -1.36362139346632\n",
      "2 6.7 -1.4522526431114764\n",
      "2 6.9 -1.5000000000000004\n",
      "3 0.1 -1.4751804932114163\n",
      "3 0.2 -1.5601700846660398\n",
      "3 0.3 -1.6259197414090032\n",
      "3 0.4 -1.707285476647473\n",
      "3 0.5 -1.7201546756259498\n",
      "3 0.6 -1.7333333333333336\n",
      "3 1.0 -1.7052630266806048\n",
      "3 1.1 -1.6966047745358093\n",
      "3 1.2 -1.6869685267294634\n",
      "3 1.3 -1.694601468417044\n",
      "3 1.4 -1.6683852147506761\n",
      "3 1.5 -1.6335200966063255\n",
      "3 1.6 -1.6114141111454834\n",
      "3 1.7 -1.5736986367348185\n",
      "3 1.8 -1.1680733067729085\n",
      "3 1.9 -1.053337118076089\n",
      "3 2.0 -0.9867494020549099\n",
      "3 2.1 -1.0021415419695028\n",
      "3 2.2 -1.0412164440953133\n",
      "3 2.3 -1.2479040803515387\n",
      "3 2.4 -1.36362139346632\n",
      "3 2.5 -1.5000000000000004\n",
      "split_column_index: 3, split_value: 0.6\n",
      "Left leaf: Iris-setosa, Right leaf: Iris-versicolor\n",
      "Boost Called\n",
      "Learner error: 0.6666666666666667\n",
      "Learner weight: -3.3306690738754696e-16\n",
      "1: Sample weight(sum) 0.9999999999999999\n",
      "Total stumps: 2\n",
      "New Stump Created!\n",
      "0 4.3 -1.4946844909737602\n",
      "0 4.4 -1.4815846743295016\n",
      "0 4.5 -1.4781526104417673\n",
      "0 4.6 -1.4689788872434948\n",
      "0 4.7 -1.467061141620902\n",
      "0 4.8 -1.4697546572934974\n",
      "0 4.9 -1.4241300803114882\n",
      "0 5.0 -1.4521306667915554\n",
      "0 5.1 -1.5085381043188848\n",
      "0 5.2 -1.5328755547014414\n",
      "0 5.3 -1.5429582094634502\n",
      "0 5.4 -1.5944044998424527\n",
      "0 5.5 -1.6038007411467594\n",
      "0 5.6 -1.5443877772079266\n",
      "0 5.7 -1.517828002069702\n",
      "0 5.8 -1.3911343288925608\n",
      "0 5.9 -1.3498432090013746\n",
      "0 6.0 -1.2760612390043047\n",
      "0 6.1 -1.2145137134061783\n",
      "0 6.2 -1.1541934554703015\n",
      "0 6.3 -1.0072593068581566\n",
      "0 6.4 -0.9410520398636641\n",
      "0 6.5 -0.9246784000000006\n",
      "0 6.6 -0.9376343779634377\n",
      "0 6.7 -0.9798726423296382\n",
      "0 6.8 -1.0112913953313054\n",
      "0 6.9 -1.071931859814964\n",
      "0 7.0 -1.0789303637713439\n",
      "0 7.1 -1.1012836761698546\n",
      "0 7.2 -1.1822989604069896\n",
      "0 7.3 -1.213944627299129\n",
      "0 7.4 -1.247904080351538\n",
      "0 7.6 -1.284173027989822\n",
      "0 7.7 -1.4522526431114764\n",
      "0 7.9 -1.5\n",
      "1 2.0 -1.4946844909737602\n",
      "1 2.2 -1.4370215049255917\n",
      "1 2.3 -1.420841293185043\n",
      "1 2.4 -1.414378634421867\n",
      "1 2.5 -1.2302502767637056\n",
      "1 2.6 -1.1518629941417364\n",
      "1 2.7 -1.0252000000000003\n",
      "1 2.8 -0.8816825665751054\n",
      "1 2.9 -0.8791099340390968\n",
      "1 3.0 -0.9488137990513157\n",
      "1 3.1 -1.0209602121320915\n",
      "1 3.2 -1.1690586248827435\n",
      "1 3.3 -1.2855603706082013\n",
      "1 3.4 -1.3364966157974905\n",
      "1 3.5 -1.323575276512687\n",
      "1 3.6 -1.369175827902798\n",
      "1 3.7 -1.370694332977699\n",
      "1 3.8 -1.4751804932114159\n",
      "1 3.9 -1.4815846743295016\n",
      "1 4.0 -1.4854811068053575\n",
      "1 4.1 -1.4898462757813202\n",
      "1 4.2 -1.4946844909737602\n",
      "1 4.4 -1.5\n",
      "2 1.0 -1.4946844909737602\n",
      "2 1.1 -1.4898462757813202\n",
      "2 1.2 -1.4815846743295016\n",
      "2 1.3 -1.467061141620902\n",
      "2 1.4 -1.4905846448459195\n",
      "2 1.5 -1.5863911595232458\n",
      "2 1.6 -1.658912912146352\n",
      "2 1.7 -1.7072854766474728\n",
      "2 1.9 -1.7333333333333332\n",
      "2 3.0 -1.728648828948382\n",
      "2 3.3 -1.719961505475747\n",
      "2 3.5 -1.7121674454347722\n",
      "2 3.6 -1.708603616906713\n",
      "2 3.7 -1.7052630266806048\n",
      "2 3.8 -1.7021476712669323\n",
      "2 3.9 -1.694185084850171\n",
      "2 4.0 -1.6858087591673905\n",
      "2 4.1 -1.683974137838833\n",
      "2 4.2 -1.6855893854687463\n",
      "2 4.3 -1.6882352941176468\n",
      "2 4.4 -1.6973765413469144\n",
      "2 4.5 -1.673505684210526\n",
      "2 4.6 -1.6909051972728288\n",
      "2 4.7 -1.7266730604463385\n",
      "2 4.8 -1.642021626137119\n",
      "2 4.9 -1.5184114852563373\n",
      "2 5.0 -1.399504989523488\n",
      "2 5.1 -1.1680733067729085\n",
      "2 5.2 -1.1160108428631939\n",
      "2 5.3 -1.0721212121212125\n",
      "2 5.4 -1.0367049596309115\n",
      "2 5.5 -1.0000000000000004\n",
      "2 5.6 -0.9877441881501587\n",
      "2 5.7 -1.0128339152119703\n",
      "2 5.8 -1.0589073692248954\n",
      "2 5.9 -1.1012836761698546\n",
      "2 6.0 -1.1529711361310135\n",
      "2 6.1 -1.247904080351538\n",
      "2 6.3 -1.284173027989822\n",
      "2 6.4 -1.322746999405823\n",
      "2 6.6 -1.3636213934663197\n",
      "2 6.7 -1.4522526431114764\n",
      "2 6.9 -1.5\n",
      "3 0.1 -1.4751804932114159\n",
      "3 0.2 -1.5601700846660398\n",
      "3 0.3 -1.625919741409003\n",
      "3 0.4 -1.7072854766474728\n",
      "3 0.5 -1.72015467562595\n",
      "3 0.6 -1.7333333333333332\n",
      "3 1.0 -1.7052630266806048\n",
      "3 1.1 -1.696604774535809\n",
      "3 1.2 -1.6869685267294634\n",
      "3 1.3 -1.6946014684170438\n",
      "3 1.4 -1.668385214750676\n",
      "3 1.5 -1.6335200966063252\n",
      "3 1.6 -1.6114141111454832\n",
      "3 1.7 -1.5736986367348185\n",
      "3 1.8 -1.1680733067729085\n",
      "3 1.9 -1.0533371180760895\n",
      "3 2.0 -0.9867494020549104\n",
      "3 2.1 -1.002141541969503\n",
      "3 2.2 -1.041216444095313\n",
      "3 2.3 -1.247904080351538\n",
      "3 2.4 -1.3636213934663197\n",
      "3 2.5 -1.5\n",
      "split_column_index: 3, split_value: 0.6\n",
      "Left leaf: Iris-setosa, Right leaf: Iris-versicolor\n",
      "Boost Called\n",
      "Learner error: 0.6666666666666666\n",
      "Learner weight: 2.220446049250313e-16\n",
      "2: Sample weight(sum) 1.0\n",
      "Total stumps: 3\n",
      "New Stump Created!\n",
      "0 4.3 -1.4946844909737604\n",
      "0 4.4 -1.4815846743295022\n",
      "0 4.5 -1.4781526104417673\n",
      "0 4.6 -1.468978887243495\n",
      "0 4.7 -1.4670611416209025\n",
      "0 4.8 -1.4697546572934976\n",
      "0 4.9 -1.4241300803114885\n",
      "0 5.0 -1.4521306667915561\n",
      "0 5.1 -1.508538104318885\n",
      "0 5.2 -1.5328755547014419\n",
      "0 5.3 -1.5429582094634506\n",
      "0 5.4 -1.5944044998424531\n",
      "0 5.5 -1.6038007411467599\n",
      "0 5.6 -1.544387777207927\n",
      "0 5.7 -1.5178280020697026\n",
      "0 5.8 -1.3911343288925613\n",
      "0 5.9 -1.3498432090013748\n",
      "0 6.0 -1.2760612390043051\n",
      "0 6.1 -1.2145137134061788\n",
      "0 6.2 -1.1541934554703017\n",
      "0 6.3 -1.0072593068581563\n",
      "0 6.4 -0.9410520398636637\n",
      "0 6.5 -0.9246784000000001\n",
      "0 6.6 -0.9376343779634375\n",
      "0 6.7 -0.9798726423296384\n",
      "0 6.8 -1.0112913953313056\n",
      "0 6.9 -1.0719318598149643\n",
      "0 7.0 -1.078930363771344\n",
      "0 7.1 -1.1012836761698548\n",
      "0 7.2 -1.1822989604069898\n",
      "0 7.3 -1.2139446272991292\n",
      "0 7.4 -1.2479040803515387\n",
      "0 7.6 -1.2841730279898225\n",
      "0 7.7 -1.4522526431114764\n",
      "0 7.9 -1.5000000000000004\n",
      "1 2.0 -1.4946844909737604\n",
      "1 2.2 -1.4370215049255923\n",
      "1 2.3 -1.4208412931850434\n",
      "1 2.4 -1.4143786344218676\n",
      "1 2.5 -1.230250276763706\n",
      "1 2.6 -1.1518629941417364\n",
      "1 2.7 -1.0252000000000008\n",
      "1 2.8 -0.8816825665751051\n",
      "1 2.9 -0.8791099340390965\n",
      "1 3.0 -0.9488137990513157\n",
      "1 3.1 -1.020960212132092\n",
      "1 3.2 -1.169058624882744\n",
      "1 3.3 -1.2855603706082013\n",
      "1 3.4 -1.3364966157974907\n",
      "1 3.5 -1.3235752765126876\n",
      "1 3.6 -1.3691758279027983\n",
      "1 3.7 -1.370694332977699\n",
      "1 3.8 -1.4751804932114163\n",
      "1 3.9 -1.4815846743295022\n",
      "1 4.0 -1.4854811068053577\n",
      "1 4.1 -1.489846275781321\n",
      "1 4.2 -1.4946844909737604\n",
      "1 4.4 -1.5000000000000004\n",
      "2 1.0 -1.4946844909737604\n",
      "2 1.1 -1.489846275781321\n",
      "2 1.2 -1.4815846743295022\n",
      "2 1.3 -1.4670611416209025\n",
      "2 1.4 -1.4905846448459197\n",
      "2 1.5 -1.5863911595232463\n",
      "2 1.6 -1.658912912146352\n",
      "2 1.7 -1.707285476647473\n",
      "2 1.9 -1.7333333333333336\n",
      "2 3.0 -1.7286488289483821\n",
      "2 3.3 -1.719961505475747\n",
      "2 3.5 -1.7121674454347724\n",
      "2 3.6 -1.7086036169067134\n",
      "2 3.7 -1.7052630266806048\n",
      "2 3.8 -1.7021476712669323\n",
      "2 3.9 -1.6941850848501714\n",
      "2 4.0 -1.6858087591673907\n",
      "2 4.1 -1.6839741378388338\n",
      "2 4.2 -1.6855893854687465\n",
      "2 4.3 -1.6882352941176475\n",
      "2 4.4 -1.6973765413469144\n",
      "2 4.5 -1.673505684210527\n",
      "2 4.6 -1.6909051972728293\n",
      "2 4.7 -1.7266730604463387\n",
      "2 4.8 -1.6420216261371194\n",
      "2 4.9 -1.5184114852563377\n",
      "2 5.0 -1.3995049895234881\n",
      "2 5.1 -1.1680733067729085\n",
      "2 5.2 -1.1160108428631936\n",
      "2 5.3 -1.0721212121212123\n",
      "2 5.4 -1.0367049596309112\n",
      "2 5.5 -1.0\n",
      "2 5.6 -0.9877441881501582\n",
      "2 5.7 -1.0128339152119703\n",
      "2 5.8 -1.0589073692248954\n",
      "2 5.9 -1.1012836761698548\n",
      "2 6.0 -1.1529711361310135\n",
      "2 6.1 -1.2479040803515387\n",
      "2 6.3 -1.2841730279898225\n",
      "2 6.4 -1.3227469994058232\n",
      "2 6.6 -1.36362139346632\n",
      "2 6.7 -1.4522526431114764\n",
      "2 6.9 -1.5000000000000004\n",
      "3 0.1 -1.4751804932114163\n",
      "3 0.2 -1.5601700846660398\n",
      "3 0.3 -1.6259197414090032\n",
      "3 0.4 -1.707285476647473\n",
      "3 0.5 -1.7201546756259498\n",
      "3 0.6 -1.7333333333333336\n",
      "3 1.0 -1.7052630266806048\n",
      "3 1.1 -1.6966047745358093\n",
      "3 1.2 -1.6869685267294634\n",
      "3 1.3 -1.6946014684170443\n",
      "3 1.4 -1.6683852147506761\n",
      "3 1.5 -1.6335200966063255\n",
      "3 1.6 -1.6114141111454834\n",
      "3 1.7 -1.5736986367348185\n",
      "3 1.8 -1.1680733067729085\n",
      "3 1.9 -1.053337118076089\n",
      "3 2.0 -0.9867494020549099\n",
      "3 2.1 -1.0021415419695028\n",
      "3 2.2 -1.0412164440953133\n",
      "3 2.3 -1.2479040803515387\n",
      "3 2.4 -1.36362139346632\n",
      "3 2.5 -1.5000000000000004\n",
      "split_column_index: 3, split_value: 0.6\n",
      "Left leaf: Iris-setosa, Right leaf: Iris-versicolor\n",
      "Boost Called\n",
      "Learner error: 0.6666666666666667\n",
      "Learner weight: -3.3306690738754696e-16\n",
      "3: Sample weight(sum) 1.0\n",
      "Total stumps: 4\n",
      "New Stump Created!\n",
      "0 4.3 -1.4946844909737602\n",
      "0 4.4 -1.4815846743295016\n",
      "0 4.5 -1.4781526104417673\n",
      "0 4.6 -1.4689788872434948\n",
      "0 4.7 -1.467061141620902\n",
      "0 4.8 -1.4697546572934974\n",
      "0 4.9 -1.4241300803114882\n",
      "0 5.0 -1.4521306667915554\n",
      "0 5.1 -1.5085381043188848\n",
      "0 5.2 -1.5328755547014414\n",
      "0 5.3 -1.5429582094634502\n",
      "0 5.4 -1.5944044998424527\n",
      "0 5.5 -1.6038007411467594\n",
      "0 5.6 -1.5443877772079266\n",
      "0 5.7 -1.517828002069702\n",
      "0 5.8 -1.3911343288925608\n",
      "0 5.9 -1.3498432090013746\n",
      "0 6.0 -1.2760612390043047\n",
      "0 6.1 -1.2145137134061783\n",
      "0 6.2 -1.1541934554703013\n",
      "0 6.3 -1.0072593068581566\n",
      "0 6.4 -0.9410520398636641\n",
      "0 6.5 -0.9246784000000006\n",
      "0 6.6 -0.9376343779634377\n",
      "0 6.7 -0.9798726423296382\n",
      "0 6.8 -1.0112913953313052\n",
      "0 6.9 -1.071931859814964\n",
      "0 7.0 -1.0789303637713439\n",
      "0 7.1 -1.1012836761698546\n",
      "0 7.2 -1.1822989604069896\n",
      "0 7.3 -1.213944627299129\n",
      "0 7.4 -1.247904080351538\n",
      "0 7.6 -1.284173027989822\n",
      "0 7.7 -1.4522526431114764\n",
      "0 7.9 -1.5\n",
      "1 2.0 -1.4946844909737602\n",
      "1 2.2 -1.4370215049255917\n",
      "1 2.3 -1.420841293185043\n",
      "1 2.4 -1.414378634421867\n",
      "1 2.5 -1.2302502767637056\n",
      "1 2.6 -1.1518629941417364\n",
      "1 2.7 -1.0252000000000003\n",
      "1 2.8 -0.8816825665751054\n",
      "1 2.9 -0.8791099340390967\n",
      "1 3.0 -0.9488137990513155\n",
      "1 3.1 -1.0209602121320913\n",
      "1 3.2 -1.1690586248827435\n",
      "1 3.3 -1.2855603706082013\n",
      "1 3.4 -1.3364966157974905\n",
      "1 3.5 -1.323575276512687\n",
      "1 3.6 -1.369175827902798\n",
      "1 3.7 -1.370694332977699\n",
      "1 3.8 -1.4751804932114159\n",
      "1 3.9 -1.4815846743295016\n",
      "1 4.0 -1.4854811068053575\n",
      "1 4.1 -1.4898462757813202\n",
      "1 4.2 -1.4946844909737602\n",
      "1 4.4 -1.5\n",
      "2 1.0 -1.4946844909737602\n",
      "2 1.1 -1.4898462757813202\n",
      "2 1.2 -1.4815846743295016\n",
      "2 1.3 -1.467061141620902\n",
      "2 1.4 -1.4905846448459195\n",
      "2 1.5 -1.5863911595232458\n",
      "2 1.6 -1.658912912146352\n",
      "2 1.7 -1.7072854766474728\n",
      "2 1.9 -1.7333333333333332\n",
      "2 3.0 -1.728648828948382\n",
      "2 3.3 -1.719961505475747\n",
      "2 3.5 -1.7121674454347722\n",
      "2 3.6 -1.708603616906713\n",
      "2 3.7 -1.7052630266806048\n",
      "2 3.8 -1.7021476712669323\n",
      "2 3.9 -1.694185084850171\n",
      "2 4.0 -1.6858087591673905\n",
      "2 4.1 -1.683974137838833\n",
      "2 4.2 -1.6855893854687463\n",
      "2 4.3 -1.6882352941176468\n",
      "2 4.4 -1.6973765413469144\n",
      "2 4.5 -1.673505684210526\n",
      "2 4.6 -1.6909051972728288\n",
      "2 4.7 -1.7266730604463385\n",
      "2 4.8 -1.642021626137119\n",
      "2 4.9 -1.5184114852563373\n",
      "2 5.0 -1.3995049895234877\n",
      "2 5.1 -1.1680733067729085\n",
      "2 5.2 -1.1160108428631936\n",
      "2 5.3 -1.0721212121212123\n",
      "2 5.4 -1.0367049596309115\n",
      "2 5.5 -1.0000000000000004\n",
      "2 5.6 -0.9877441881501587\n",
      "2 5.7 -1.0128339152119703\n",
      "2 5.8 -1.0589073692248951\n",
      "2 5.9 -1.1012836761698546\n",
      "2 6.0 -1.1529711361310135\n",
      "2 6.1 -1.247904080351538\n",
      "2 6.3 -1.284173027989822\n",
      "2 6.4 -1.322746999405823\n",
      "2 6.6 -1.3636213934663197\n",
      "2 6.7 -1.4522526431114764\n",
      "2 6.9 -1.5\n",
      "3 0.1 -1.4751804932114159\n",
      "3 0.2 -1.5601700846660398\n",
      "3 0.3 -1.625919741409003\n",
      "3 0.4 -1.7072854766474728\n",
      "3 0.5 -1.72015467562595\n",
      "3 0.6 -1.7333333333333332\n",
      "3 1.0 -1.7052630266806048\n",
      "3 1.1 -1.696604774535809\n",
      "3 1.2 -1.6869685267294634\n",
      "3 1.3 -1.6946014684170438\n",
      "3 1.4 -1.668385214750676\n",
      "3 1.5 -1.6335200966063252\n",
      "3 1.6 -1.6114141111454832\n",
      "3 1.7 -1.5736986367348185\n",
      "3 1.8 -1.1680733067729085\n",
      "3 1.9 -1.0533371180760893\n",
      "3 2.0 -0.9867494020549102\n",
      "3 2.1 -1.0021415419695028\n",
      "3 2.2 -1.041216444095313\n",
      "3 2.3 -1.247904080351538\n",
      "3 2.4 -1.3636213934663197\n",
      "3 2.5 -1.5\n",
      "split_column_index: 3, split_value: 0.6\n",
      "Left leaf: Iris-setosa, Right leaf: Iris-versicolor\n",
      "Boost Called\n",
      "Learner error: 0.6666666666666665\n",
      "Learner weight: 6.661338147750939e-16\n",
      "4: Sample weight(sum) 1.0\n",
      "Total stumps: 5\n"
     ]
    }
   ],
   "source": [
    "wdd = abc.fit(df.iloc[:, :-1].values, df.iloc[:, -1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([1, 2, 3])\n",
    "a2 = np.array([2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 * a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = np.array(['c1', 'c1', 'c1', 'c3', 'c2', 'c2', 'c2', 'c2', 'c3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = np.array([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, c_index, c_cnt = np.unique(lb, return_counts=True, return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.8, 0.4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.take(sw, np.where(lb == lb[value_index])[0]).sum() for value_index in c_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15789474, 0.52631579, 0.31578947])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([0.2,0.5,0.6]) * np.array([3, 4, 2])) / sum(np.array([0.2,0.5,0.6]) * np.array([3, 4, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_gini_index(data, sample_weight):\n",
    "    \"\"\"\n",
    "    Calculate weighted gini index\n",
    "    \"\"\"\n",
    "    label_column = data\n",
    "    #_, counts = np.unique(label_column, return_counts=True)\n",
    "    _, value_indexes, counts = np.unique(label_column, return_counts=True, return_index=True)\n",
    "    # Get summed weights for each class\n",
    "    class_weights = np.array([np.take(sample_weight, np.where(label_column == label_column[value_index])[0]).sum() for value_index in value_indexes])\n",
    "\n",
    "    #probabilities = counts / counts.sum()\n",
    "    weighted_classes = counts * class_weights\n",
    "    normalized_weighted_classes = weighted_classes / sum(weighted_classes)\n",
    "\n",
    "    weighted_gini_impurity = 1 - sum(normalized_weighted_classes**2)\n",
    "\n",
    "    return weighted_gini_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = np.array([2, 2, 1, 1])\n",
    "wp = np.array([0.25, 0.15, 0.35, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_weighted_gini_index(xp, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(i for i in range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.71828183,  7.3890561 , 20.08553692])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['a'],\n",
       "       ['b'],\n",
       "       ['c']], dtype='<U1')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgg = np.array(['a', 'b', 'c'])\n",
    "xgg = xgg[:, np.newaxis]\n",
    "xgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'b'], dtype='<U1')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgp = np.array(['a', 'b', 'b'])\n",
    "xgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [False,  True,  True],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xgp == xgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xgp == xgg).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 2, 0]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((xgp == xgg).T * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 0],\n",
       "       [0, 4, 0],\n",
       "       [0, 4, 0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([((xgp == xgg).T * 2), ((xgp == xgg).T * 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((xgp == xgg) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((xgp == xgg).T * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [0, 2],\n",
       "       [0, 2]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtt = np.array([[2, 0, 0], [0, 2, 2]]).T\n",
    "vtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtt[:, 0] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2,  0],\n",
       "       [ 0,  2],\n",
       "       [ 0,  2]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtt.sum(axis=1) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = np.array([['class1'], ['class2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['class1'],\n",
       "       ['class2'],\n",
       "       ['class1'],\n",
       "       ['class2'],\n",
       "       ['class2']], dtype='<U6')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.take([False, True, False, True, True], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostRegressor():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/4 * True * (1/2 > 0) * (-1 < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict called\n"
     ]
    }
   ],
   "source": [
    "predicc = wdd.predict(df.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_classification(df.iloc[:, -1].values, predicc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-00015deed469>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_estimators'"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-a3a80d8fcbac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.fit(df.iloc[:, :-1].values, df.iloc[:, -1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_pred = clf.predict(df.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_classification(df.iloc[:, -1].values, sk_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghu = np.array([0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.00666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667, 0.02666667])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.00333333, 0.00333333, 0.00333333, 0.00333333, 0.00333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghu / ghu.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdddf['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object),\n",
       " array([50, 50, 50], dtype=int64))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.values[:, -1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object),\n",
       " array([30, 21, 99], dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(wdd[:, -1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e4dd538415fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwdd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[1;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    778\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ravel_and_check_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m     \u001b[0mbin_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_bin_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[1;31m# Histogram is an integer or a float array depending on the weights.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36m_get_bin_edges\u001b[1;34m(a, bins, range, weights)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`bins` must be positive, when an integer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m         \u001b[0mfirst_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_outer_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36m_get_outer_edges\u001b[1;34m(a, range)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[0mfirst_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_edge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             raise ValueError(\n\u001b[0;32m    315\u001b[0m                 \"autodetected range of [{}, {}] is not finite\".format(first_edge, last_edge))\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "np.histogram(wdd[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.values[:, -1]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = df.values[:, -1][:3] == ['Iris-setos', 'Iris-setosa', 'Iris-setosa']\n",
    "np.mean(np.average(ft, weights=np.array([0.2, 0.4, 0.4]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABC():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        print('Instantiate:',  name)\n",
    "    def print_myname(self, myname):\n",
    "        print(\"My name is\", myname)\n",
    "        self.predict()\n",
    "    def hello1(self):\n",
    "        print('h1')\n",
    "    def hello2(self):\n",
    "        self.hello1()\n",
    "        \n",
    "    def a2(self, name):\n",
    "        print('a2', name)\n",
    "    def a3(self, name):\n",
    "        print('a3', name)\n",
    "    def az(self, m_func):\n",
    "        m_func('pratik')\n",
    "        \n",
    "    def func_mix(self):\n",
    "        self.az(m_func=self.a2)\n",
    "        self.az(m_func=self.a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(ABC):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "    def something_about_me(self, name):\n",
    "        self.print_myname(name)\n",
    "    def predict(self):\n",
    "        print('predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiate: A\n"
     ]
    }
   ],
   "source": [
    "stored = A('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is pratik\n",
      "predicted\n"
     ]
    }
   ],
   "source": [
    "stored.something_about_me('pratik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is pratik\n",
      "predicted\n"
     ]
    }
   ],
   "source": [
    "stored.print_myname('pratik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 pratik\n",
      "a3 pratik\n"
     ]
    }
   ],
   "source": [
    "stored.func_mix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a2() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-321-7373c228accd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstored\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: a2() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "stored.a2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-edfbb22029d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "np.unique(X[:, feature_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = np.array([\n",
    "       [2, 4, 1, 1, 0],\n",
    "       [5, 2, 1, 0, 0],\n",
    "       [0, 8, 0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2, 0], dtype=int64))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tf[:, 2], return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a5a9ae7ac93f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "np.concatenate((df.iloc[:, :-1].values, df.iloc[:, -1].values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate((df.iloc[:, :-1].values, np.expand_dims(df.iloc[:, -1].values, axis=1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, :-1].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, -1].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.expand_dims(df.iloc[:, -1].values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33, 0.66, 0.99])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = np.cumsum(np.array([0.33, 0.33, 0.33]))\n",
    "vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47607097125121944"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ide = np.random.random_sample()\n",
    "ide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  2,  1],\n",
       "       [22,  1,  2,  1],\n",
       "       [33,  1,  2,  1],\n",
       "       [44,  1,  2,  1],\n",
       "       [55,  1,  2,  1]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idr = np.array([[1, 1, 2, 1], [22, 1, 2, 1], [33, 1, 2, 1], [44, 1, 2, 1], [55, 1, 2, 1]])\n",
    "idr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = [0, 0, 1, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  2,  1],\n",
       "       [ 1,  1,  2,  1],\n",
       "       [22,  1,  2,  1],\n",
       "       [33,  1,  2,  1],\n",
       "       [33,  1,  2,  1]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idr[idd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = np.array([0.4, 0.1, 0.1, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.5, 0.6, 0.8, 1. ])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data_by_weight(data, sample_weight):\n",
    "    \"\"\"\n",
    "    Construct an new input, iteratively sampled over distribution \n",
    "    formed by passed sample_weight.\n",
    "    \n",
    "    Note: \n",
    "    Learn more about this technique: https://youtu.be/LsK-xG1cLYA (Statquest)\n",
    "    \"\"\"\n",
    "    n_samples, _ = np.shape(data)\n",
    "    # Intialize array to hold sampled index  \n",
    "    sampled_indices = []\n",
    "    # Perform cumulative summation over sample_weight to create buckets\n",
    "    sample_weight_buckets = np.cumsum(sample_weight)\n",
    "    # Keeping sampling 'n_samples' times\n",
    "    for _ in range(n_samples):\n",
    "        # Generate a random number between 0 and 1\n",
    "        random_num = np.random.random_sample()\n",
    "        # Find the bucket Eg: weight buckets [0.33, 0.66, 0.99] and random number = 0.47\n",
    "        # then index 1 will be selected (since cumsum value is 0.66)\n",
    "        bucket_index = np.where(sample_weight_buckets > random_num)[0][0]\n",
    "        \n",
    "        sampled_indices.append(bucket_index)\n",
    "    # finally construct weighted data using sampled_indexes\n",
    "    weighted_data = data[sampled_indices]\n",
    "    \n",
    "    return weighted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  2,  1],\n",
       "       [ 1,  1,  2,  1],\n",
       "       [ 1,  1,  2,  1],\n",
       "       [ 1,  1,  2,  1],\n",
       "       [55,  1,  2,  1]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_by_weight(idr, sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(vt > ide)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "stf = [np.random.random_sample() for i in range(100)] \n",
    "stfr = [random.uniform(0, 1) for i in range(100)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14.,  9., 11.,  6., 15.,  6., 14.,  7.,  7., 11.]),\n",
       " array([0.00696925, 0.10549445, 0.20401964, 0.30254484, 0.40107003,\n",
       "        0.49959522, 0.59812042, 0.69664561, 0.79517081, 0.893696  ,\n",
       "        0.9922212 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(stf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12., 14., 10.,  8.,  5., 10.,  6., 12., 10., 13.]),\n",
       " array([9.60159013e-04, 9.95832402e-02, 1.98206321e-01, 2.96829402e-01,\n",
       "        3.95452484e-01, 4.94075565e-01, 5.92698646e-01, 6.91321727e-01,\n",
       "        7.89944808e-01, 8.88567889e-01, 9.87190971e-01]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(stfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
