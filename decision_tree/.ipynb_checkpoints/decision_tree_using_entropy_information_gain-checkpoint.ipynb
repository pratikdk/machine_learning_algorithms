{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree using Entropy and Information Gain as spliting metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pprint import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Iris.csv')\n",
    "df = df.drop(\"Id\", axis=1)\n",
    "df = df.rename(columns={\"species\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        label\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def train_test_split(df, test_size=0.8, random_state=None):\n",
    "    train_df = df.sample(frac=test_size, random_state=random_state)\n",
    "    test_df = df[~df.index.isin(train_df.index)]\n",
    "    return train_df.sort_index(), test_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classify with the most frequent value\n",
    "def classify_data(data_group):\n",
    "    \n",
    "    (values, counts) = np.unique(data_group[:, -1], return_counts=True)\n",
    "    most_common_value_indx = np.argmax(counts)\n",
    "    \n",
    "    return values[most_common_value_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get potential splits for each feature\n",
    "def get_potential_splits(data_group): # Split on each unique value(or each value)\n",
    "    potential_splits = {} # Can essentially make a split at each unique value\n",
    "    \n",
    "    for column_index in range(data_group.shape[1] - 1):\n",
    "        potential_splits[column_index] = np.unique(data_group[:, column_index])\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column_index, splitting_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column_index]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column_index]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= splitting_value]\n",
    "        data_above = data[split_column_values >  splitting_value]\n",
    "    \n",
    "    # feature is categorical   \n",
    "    else:\n",
    "        data_below = data[split_column_values == splitting_value]\n",
    "        data_above = data[split_column_values != splitting_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "**Entropy(feature_question)** = - (Entropy(yes_answer) + Entropy(no_answer))\n",
    "### Information Gain\n",
    "**Information_gain(feature_question)** = Entropy(all_rows_in_concern) -\n",
    "(((no. of examples in left child node) / (total no. of examples in parent node)) * (entropy of left node) + ((no. of examples in right child node) / (total no. of examples in parent node)) * (entropy of right node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate entropy\n",
    "def calculate_entropy(data_group):\n",
    "    _, counts = np.unique(data_group[:, -1], return_counts=True)\n",
    "    \n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(parent_data_group, left_data_group, right_data_group):\n",
    "    \n",
    "    # Calculate entropy for parent and left, right nodes\n",
    "    parent_group_entropy = calculate_entropy(parent_data_group)\n",
    "    left_group_entropy = calculate_entropy(left_data_group)\n",
    "    right_group_entropy = calculate_entropy(right_data_group)\n",
    "    \n",
    "    # Probabilities of left and right node\n",
    "    num_examples_parent = len(parent_data_group)\n",
    "    left_group_probability = len(left_data_group) / num_examples_parent\n",
    "    right_group_probability = len(right_data_group) / num_examples_parent\n",
    "    \n",
    "    # Final equation for IG computation\n",
    "    information_gain = parent_group_entropy - ((left_group_probability * left_group_entropy) + (right_group_probability * right_group_entropy))\n",
    "    \n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines which column/feature to split on\n",
    "def determine_best_split(data_group, potential_splits):\n",
    "    \n",
    "    max_information_gain = 0\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            # Go for a split \n",
    "            left_data_group, right_group_data = split_data(data_group, split_column_index=column_index, splitting_value=value)\n",
    "            current_information_gain = information_gain(data_group, left_data_group, right_group_data)\n",
    "            \n",
    "            if current_information_gain >= max_information_gain:\n",
    "                max_information_gain = current_information_gain\n",
    "                best_split_column_index = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column_index, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Decision_Tree(df, counter=0, min_samples=2, max_depth=5):\n",
    "    ### Data preparation\n",
    "    if counter == 0: # Declare before tree building(to skip re-declarations when doing recursions)\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df # this is basically a numpy array ()\n",
    "        \n",
    "    ### Base cases\n",
    "    ## Check if, # To conclude as a Leaf node\n",
    "    # data(rows) are of same label or\n",
    "    # data(rows) have length < min_samples\n",
    "    # if tree has crossed a depth threshold (manitored using counter)\n",
    "    if (np.unique(data[:, -1]).size == 1) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    ### Mighty-Greedy Recursion\n",
    "    # The tree is constructed in a depth first on Left, back traversal on Right fashion.\n",
    "    else: # Its a dictionary (haven't exploited our base case)/ hence ask Question and split\n",
    "        counter += 1\n",
    "        \n",
    "        # Call for help using our helper functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column_index, split_value = determine_best_split(data, potential_splits)\n",
    "        left_data_group, right_data_group = split_data(data, split_column_index, split_value)\n",
    "        \n",
    "        # Check for empty data\n",
    "        if len(left_data_group) == 0 or len(right_data_group) == 0: # Either nothing or a pure group\n",
    "            classification = classify_data(data)\n",
    "            return classification # Classify as leaf \n",
    "        \n",
    "        # determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column_index]\n",
    "        type_of_feature = FEATURE_TYPES[split_column_index]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "        else: # feature is categorical\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "            \n",
    "        # Instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # Find answers: Find(by questioning) or conclude(classify with leaf)\n",
    "        # Recursion starts here.\n",
    "        # First completely expand tree on left(yes) questions/answers, followed by answering right while traversing back until root is reached.\n",
    "        yes_answer = build_Decision_Tree(left_data_group, counter, min_samples, max_depth)\n",
    "        no_answer = build_Decision_Tree(right_data_group, counter, min_samples, max_depth)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, 0.8, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'petal_width <= 0.6': ['Iris-setosa',\n",
      "                        {'petal_width <= 1.7': [{'petal_length <= 4.9': ['Iris-versicolor',\n",
      "                                                                         'Iris-virginica']},\n",
      "                                                {'petal_length <= 4.8': ['Iris-versicolor',\n",
      "                                                                         'Iris-virginica']}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree = build_Decision_Tree(train_df, max_depth=3)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "    \n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0] # Yes\n",
    "        else:\n",
    "            answer = tree[question][1] # No\n",
    "            \n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0] # Yes\n",
    "        else:\n",
    "            answer = tree[question][1] # No\n",
    "    \n",
    "    # base case\n",
    "    if not isinstance(answer, dict): # Answer found\n",
    "        return answer\n",
    "    # recursive part\n",
    "    else: # Follow along the tree\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "\n",
    "    df[\"classification\"] = df.apply(classify_example, args=(tree,), axis=1)\n",
    "    df[\"classification_correct\"] = df[\"classification\"] == df[\"label\"]\n",
    "    \n",
    "    accuracy = df[\"classification_correct\"].mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
